# 消息队列

## 消息队列基础

### 消息队列作用

**优点**

**1. 解耦**

将消息写入消息队列，需要消息的系统自己从消息队列中订阅，从而发布方不需要做任何修改。从而系统间减少强依赖性，系统间解耦。

**2.异步**

将消息写入消息队列，非必要的业务逻辑以异步的方式运行，加快响应速度。可以更快地返回结果；减少等待，自然实现了步骤之间的并发，提升系统总体的性能。

**3.削峰**

系统慢慢的按照数据库能处理的并发量，从消息队列中慢慢拉取消息。在生产中，这个短暂的高峰期积压是允许的。

**缺点**：

1.系统复杂性增加。会产生消息**重复消费**、**消息丢失**、**消息的顺序消费**等问题。

2.数据一致性问题。

3.可用性降低。系统引入的外部依赖越多，越容易出问题。

### MQ选型

| 特性                     | ActiveMQ                              | RabbitMQ                                           | RocketMQ                                                     | Kafka                                                        |
| ------------------------ | ------------------------------------- | -------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 单机吞吐量               | 万级，比 RocketMQ、Kafka 低一个数量级 | 同 ActiveMQ                                        | 10 万级，支撑高吞吐                                          | 10 万级，高吞吐，一般配合大数据类的系统来进行实时数据计算、日志采集等场景 |
| topic 数量对吞吐量的影响 |                                       |                                                    | topic 可以达到几百/几千的级别，吞吐量会有较小幅度的下降，这是 RocketMQ 的一大优势，在同等机器下，可以支撑大量的 topic | topic 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，Kafka 尽量保证 topic 数量不要过多，如果要支撑大规模的 topic，需要增加更多的机器资源 |
| 时效性                   | ms 级                                 | 微秒级，这是 RabbitMQ 的一大特点，延迟最低         | ms 级                                                        | 延迟在 ms 级以内                                             |
| 可用性                   | 高，基于主从架构实现高可用            | 同 ActiveMQ                                        | 非常高，分布式架构                                           | 非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用 |
| 消息可靠性               | 有较低的概率丢失数据                  | 基本不丢                                           | 经过参数优化配置，可以做到 0 丢失                            | 同 RocketMQ                                                  |
| 功能支持                 | MQ 领域的功能极其完备                 | 基于 erlang 开发，并发能力很强，性能极好，延时很低 | MQ 功能较为完善，还是分布式的，扩展性好                      | 功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用 |

综上，各种对比之后，有如下建议：

一般的业务系统要引入 MQ，最早大家都用 ActiveMQ，但是现在确实大家用的不多了，没经过大规模吞吐量场景的验证，社区也不是很活跃，所以大家还是算了吧，我个人不推荐用这个了；

后来大家开始用 RabbitMQ，但是确实 erlang 语言阻止了大量的 Java 工程师去深入研究和掌控它，对公司而言，几乎处于不可控的状态，但是确实人家是开源的，比较稳定的支持，活跃度也高；

不过现在确实越来越多的公司会去用 RocketMQ，确实很不错，毕竟是阿里出品，但社区可能有突然黄掉的风险（目前 RocketMQ 已捐给 [Apache](https://github.com/apache/rocketmq)，但 GitHub 上的活跃度其实不算高）对自己公司技术实力有绝对自信的，推荐用 RocketMQ，否则回去老老实实用 RabbitMQ 吧，人家有活跃的开源社区，绝对不会黄。

所以**中小型公司**，技术实力较为一般，技术挑战不是特别高，用 RabbitMQ 是不错的选择；**大型公司**，基础架构研发实力较强，用 RocketMQ 是很好的选择。

如果是**大数据领域**的实时计算、日志采集等场景，用 Kafka 是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范。

### 消息模型

## 消息队列高可用

### RabbitMQ 的高可用性

RabbitMQ 有三种模式：单机模式、普通集群模式、镜像集群模式。

单机模式

demo级

普通集群模式（非高可用）

队列的元数据存在于多个实例中，但是消息不存在多个实例中，每次多台机器上启动多个 rabbitmq 实例，每个机器启动一个。

- 优点：可以多个机器消费消息，可以提高消费的吞吐量
- 缺点：可能会在 rabbitmq 内部产生大量的数据传输 ；可用性基本没保障，queue 所在机器宕机，就没办法消费了

没有高可用性可言

镜像集群模式（高可用，非分布式）

队列的元数据和消息都会存在于多个实例中，每次写消息到 queue的时候，都会自动把消息到多个实例的 queue 里进行消息同步。也就 是每个节点上都有这个 queue 的一个完整镜像（这个 queue的全部数据）。任何一个节点宕机了，其他节点还包含这个 queue的完整数据，其他 consumer 都可以到其他活着的节点上去消费数据都是 OK 的。

缺点：不是分布式的，如果这个 queue的数据量很大，大到这个机器上的容量无法容纳 。

开启镜像集群模式方法：管理控制台，Admin页面下，新增一个镜像集群模式的策略，指定的时候可以要求数据同步到所有节点，也可以要求同步到指定数量的节点，然后你再次创建 queue 的时候 ，应用这个策略，就 会自动将数据同步到其他的节点上去。

### Kafka 高可用架构

broker进程就是kafka在每台机器上启动的自己的一个进程。每台机器+机器上的broker进程，就可以认为是 kafka集群中的一个节点。

你创建一个 topic,这个topic可以划分为多个 partition,每个 partition 可以存在于不同的 broker 上，每个 partition就存放一部分数据。

这就是天然的分布式消息队列，也就是说一个 topic的数据，是分散放在 多个机器上的，每个机器就放一部分数据。

## 如何保证消息的有序性？

有序性分：**全局有序和部分有序**。

### 全局有序

如果要保证消息的全局有序，首先只能由一个生产者往`Topic`发送消息，并且一个`Topic`内部只能有一个队列（分区）。消费者也必须是单线程消费这个队列。这样的消息就是全局有序的！

不过一般情况下我们都不需要全局有序，即使是同步`MySQL Binlog`也只需要保证单表消息有序即可。

![img](https://mmbiz.qpic.cn/mmbiz_png/azicia1hOY6Q9ic077HnPNN4qjjtPunia79BYUq2KkvOfuiammjicFt5RoKeTia6mOfTLibE5JnOHY2gfPXyoGCvs38I9g/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

### 部分有序

因此绝大部分的有序需求是部分有序，部分有序我们就可以将`Topic`内部划分成我们需要的队列数，把消息通过特定的策略发往固定的队列中，然后每个队列对应一个单线程处理的消费者。这样即完成了部分有序的需求，又可以通过队列数量的并发来提高消息处理效率。

![img](https://mmbiz.qpic.cn/mmbiz_png/azicia1hOY6Q9ic077HnPNN4qjjtPunia79BRzzgWJANoENTNLibj953KiaK9vlJjPqKcibGU9lZoYG4U2dFWcqbiagWyQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

## 如何保证消息不丢失？

就市面上常见的消息队列而言，只要**配置得当**，消息就不会丢。

![img](https://gitee.com/adambang/pic/raw/master/20201125090312.png)

可以看到一共有三个阶段，分别是**生产消息、存储消息和消费消息**。我们从这三个阶段分别入手来看看如何确保消息不会丢失。

### **生产消息**

**在生产阶段，消息队列通过最常用的请求确认机制，来保证消息的可靠传递。**

生产者发送消息至`Broker`，需要处理`Broker`的响应，不论是同步还是异步发送消息，同步和异步回调都需要做好`try-catch`，妥善的处理响应，如果`Broker`返回写入失败等错误消息，需要重试发送。当多次发送失败需要作报警，日志记录等。

这样就能保证在生产消息阶段消息不会丢失。

### **存储消息**

在存储阶段正常情况下，只要 Broker 在正常运行，就不会出现丢失消息的问题，但是如果 Broker 出现了故障，比如进程死掉了或者服务器宕机了，还是可能会丢失消息的。

存储消息阶段需要在**消息刷盘之后**再给生产者响应，假设消息写入缓存中就返回响应，那么机器突然断电这消息就没了，而生产者以为已经发送成功了。

如果`Broker`是集群部署，有多副本机制，即消息不仅仅要写入当前`Broker`,还需要写入副本机中。那配置成至少写入两台机子后再给生产者响应。这样基本上就能保证存储的可靠了。

### **消费消息**

需要考虑拿到消息放在内存之后消费者就宕机了怎么办。所以我们应该在**消费者真正执行完业务逻辑之后，再发送给`Broker`消费成功**，这才是真正的消费了。

所以只要我们在消息业务逻辑处理完成之后再给`Broker`响应，那么消费阶段消息就不会丢失。



可以看出，保证消息的可靠性需要**三方配合**。

`生产者`需要处理好`Broker`的响应，出错情况下利用重试、报警等手段。

`Broker`需要控制响应的时机，单机情况下是消息刷盘后返回响应，集群多副本情况下，即发送至两个副本及以上的情况下再返回响应。

`消费者`需要在执行完真正的业务逻辑之后再返回响应给`Broker`。

但是要注意**消息可靠性增强了，性能就下降了**，等待消息刷盘、多副本同步后返回都会影响性能。因此还是看业务，例如日志的传输可能丢那么一两条关系不大，因此没必要等消息刷盘再响应

## 如何保证消息不被重复消费？幂等性

一般解决重复消息的办法是，在消费端，让我们消费消息的操作具备幂等性。

幂等：一个数据或者一个请求，给你重复来多次，你得确保对应的数据是不会改变的，不能出错。
思路：

1. 利用数据库的唯一约束实现幂等

2. 为更新的数据设置前置条件。如果数据要写库，首先检查下主键，如果有数据，则不插入，进行一次update。

3.  记录并检查操作

   生产者发送消息的时候带上一个全局唯一的id,消费者拿到消息后，先根据这个id去 redis里查一下，之前有没消费过，没有消费过就处理，并且写入这个 id 到 redis，如果消费过了，则不处理。

4. 如果是写 redis，就没问题，反正每次都是 set ，天然幂等性

## 消息队列延迟以及过期失效

消费端出了问题，不消费了或者消费极其慢。接着坑爹了，你的消息队列集群的磁盘都快写满了 ，都没人消费，怎么办？积压了几个小时，rabbitmq设置了消息过期时间后就没了，怎么办？

场景：几千万条数据再 MQ 里积压了七八个小时。

**快速处理积压的消息**

一个消费者一秒是 1000 条，一秒 3 个消费者是 3000 条，一分钟是 18W 条，1000 多 W 条需要一个小时恢复。

步骤：

- 先修复 consumer 的问题，确保其恢复消费速度，然后将现有的 consumer 都停掉
- 新建一个topic,partition是原来的 10 倍，临时建立好原先 10 倍或者 20 倍的 queue 数量
- 然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的 10 倍数量的 queue
- 接着临时征用 10 倍的机器来部署 consumer,每一批 consumer 消费一个临时 queue 的数据
- 这种做法相当 于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常 10 倍速度
- 等快速消费完积压数据之后，恢复原先部署架构 ，重新用原先的 consumer机器消费消息

原来 3 个消费者需要 1 个小时可以搞定，现在 30 个临时消费者需要 10 分钟就可以搞定。

如果用的 rabbitmq，并且设置了过期时间，如果此消费在 queue里积压超过一定的时间会被 rabbitmq清理掉，数据直接搞丢。
这个时候开始写程序，将丢失的那批 数据查出来，然后重新灌入mq里面，把白天丢的数据补回来。

如果消息积压mq，长时间没被处理掉，导致mq快写完满了，你临时写一个程序，接入数据来消费，写到一个临时的mq里，再让其他消费者慢慢消费 或者消费一个丢弃一个，都不要了，快速消费掉所有的消息，然后晚上补数据。

## **如何设计消息队列中间件架构**

- mq要支持可伸缩性，快速扩容。设计一个分布式的 MQ，broker->topic->partition，每个 partition 放一个机器，就存一部分数据。如果现在资源不够，给 topic 增加 partition ，然后做数据迁移，增加机器。
- mq数据落磁盘，避免进程挂了数据丢了，顺序写，这样就没有磁盘随机读写的寻址开销，磁盘顺序读写的性能是很高的，这个就是 kafka的思路。
- mq高可用性。多副本->leader & follower-> broker 挂了重新选举 leader 对外提供服务
- 支持数据 0 丢失。
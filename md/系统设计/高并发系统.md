# 一. 系统设计基础

## 1.1 通用方法

高并发系统设计归纳起来共有三种方法。

- Scale-out（横向扩展）：分而治之是一种常见的高并发系统设计方法，采用分布式部署的方式把流量分流开，让每个服务器都承担一部分并发和流量。（一般是Scale-up（纵向扩展）单机性能挖掘到极限的情况）
- 缓存：使用缓存来提高系统的性能，就好比用“拓宽河道”的方式抵抗高并发大流量的冲击。
- 异步：在某些场景下，未处理完成之前我们可以让请求先返回，在数据准备好之后再通知请求方，这样可以在单位时间内处理更多的请求。

高并发系统的演进应该是循序渐进，以解决系统中存在的问题为目的和驱动力的。

## 1.2 架构分层

软件架构分层在软件工程中是一种常见的设计方式，它是将整体系统拆分成 N 个层次，每个层次有独立的职责，多个层次协同提供完整的功能。

分层的**好处**如下：

- 分层的设计可以简化系统设计，让不同的人专注做某一层次的事情。
- 分层之后可以做到很高的复用。
- 分层架构可以更容易做横向扩展。

分层的**不足**是可能会增加代码的复杂度。

## 1.3 系统设计目标

**高并发系统设计的三大目标：高性能、高可用、可扩展**

高并发，是指运用设计手段让系统能够处理更多的用户并发请求，也就是承担更大的流量。

### 1.3.1 高性能

**性能优化原则：**

首先，性能优化一定不能盲目，一定是问题导向的。脱离了问题，盲目地提早优化会增加系统的复杂度，浪费开发人员的时间，也因为某些优化可能会对业务上有些折中的考虑，所以也会损伤业务。

其次，性能优化也遵循“八二原则”，即你可以用 20% 的精力解决 80% 的性能问题。

再次，性能优化也要有数据支撑。在优化过程中，你要时刻了解你的优化让响应时间减少了多少，提升了多少的吞吐量。

最后，性能优化的过程是持续的。高并发的系统通常是业务逻辑相对复杂的系统，那么在这类系统中出现的性能问题通常也会有多方面的原因。

**性能的度量指标**（吞吐量和响应时间）：

度量性能的指标是系统接口的响应时间，具体的指标如下：

平均值：顾名思义，平均值是把这段时间所有请求的响应时间数据相加，再除以总请求数。平均值可以在一定程度上反应这段时间的性能，但它敏感度比较差，如果这段时间有少量慢请求时，在平均值上并不能如实地反应。

最大值：这段时间内所有请求响应时间最长的值，但它的问题又在于过于敏感了。

分位值：分位值排除了偶发极慢请求对于数据的影响，能够很好地反应这段时间的性能情况，分位值越大，对于慢请求的影响就越敏感。

**性能优化：**

1. 提高系统的处理核心数。

    但并非无限增加核心数就可以增加吞吐量，随着进程数增加，并行的任务对于资源的争夺也增加，在某
    个临界点，进程增加导致系统的性能下降，这就是性能测试中的拐点模型，所以在评估系统性能时，需要做压力测试，找到拐点。

2. 减少单次任务的响应时间。

   cpu密集型：优化算法
   io密集型：1.采用工具，linux的工具集
                   2.通过监控，对任务的每一个步骤做分时统计，从而找到任务中哪一步消耗了更多的时间

### 1.3.2 高可用

高可用性（High Availability，HA），指的是系统具备较高的无故障运行的能力。

**可用性的度量：**

MTBF（Mean Time Between Failure）是平均故障间隔的意思，代表两次故障的间隔时间，也就是系统正常运转的平均时间。这个时间越长，系统稳定性越高。

MTTR（Mean Time To Repair）表示故障的平均恢复时间，也可以理解为平均故障时间。这个值越小，故障对于用户的影响越小。

可用性与 MTBF 和 MTTR 的值息息相关，我们可以用下面的公式表示它们之间的关系：

$Availability = MTBF / (MTBF + MTTR)$

这个公式计算出的结果是一个比例，而这个比例代表着系统的可用性。

<img src="https://static001.geekbang.org/resource/image/73/75/73a87a9bc14a27c9ec9dfda1b72e1e75.jpg" alt="img" style="zoom:50%;" />

一般来说，我们的核心业务系统的可用性，需要达到四个九，非核心系统的可用性最多容忍到三个九。

**高可用思路**

1. 开发设计层面
   冗余---主备，负载均衡，failover（故障转移）
   取舍----降级，限流，熔断，超时控制

2. 运维层面
   灰度发布，故障演练，监控报警

### 1.3.3 拓展性

数据库、缓存、依赖的第三方、负载均衡、交换机带宽等等都是系统扩展时需要考虑的因素。

拆分是提升系统扩展性最重要的一个思路，它会把庞杂的系统拆分成独立的，有单一职责的模块。

存储层和业务层都可以进行拆分。

# 二. 数据库

**使用连接池避免频繁创建数据库连接的消费。**

## 2.1 主从读写分离

一般来说在主从读写分离机制中，我们将一个数据库的数据拷贝为一份或者多份，并且写入到其它的数据库服务器中，原始的数据库我们称为主库，主要负责数据的写入，拷贝的目标数据库称为从库，主要负责支持数据查询。可以看到，主从读写分离有两个技术上的关键点：

1. 一个是数据的拷贝，我们称为主从复制；
2.  在主从分离的情况下，我们如何屏蔽主从分离带来的访问数据库方式的变化，让开发同学像是在使用单一数据库一样。

### 2.1.1 主从复制

主从复制过程：

1. master提交完事务后，写入binlog
2. slave连接到master，获取binlog
3. master创建dump线程，推送binglog到slave
4. slave启动一个IO线程读取同步过来的master的binlog，记录到relay log中继日志中
5. slave再开启一个sql线程读取relay log事件并在slave执行，完成同步
6. slave记录自己的binglog

![img](https://gitee.com/adambang/pic/raw/master/20210121160120.jpeg)

**主从延迟：**

> 场景如下：
>
> 在发微博的过程中会有些同步的操作，像是更新数据库的操作，也有一些异步的操作，比如说将微博的信息同步给审核系统，所以我们在更新完主库之后，会将微博的 ID 写入消息队列，再由队列处理机依据 ID 在从库中获取微博信息再发送给审核系统。此时如果主从数据库存在延迟，会导致在从库中获取不到微博信息，整个流程会出现异常。
>
> <img src="https://gitee.com/adambang/pic/raw/master/20210121161008.jpeg" alt="img" style="zoom: 50%;" />

**解决方法**：

第一种方案是数据的冗余。你可以在发送消息队列时不仅仅发送微博 ID，而是发送队列处理机需要的所有微博信息，借此避免从数据库中重新查询数据。

第二种方案是使用缓存。我可以在同步写数据库的同时，也把微博的数据写入到 Memcached 缓存里面，这样队列处理机在获取微博信息的时候会优先查询缓存，这样也可以保证数据的一致性。

最后一种方案是查询主库。我可以在队列处理机中不查询从库而改为查询主库。不过，这种方式使用起来要慎重，要明确查询的量级不会很大，是在主库的可承受范围之内，否则会对主库造成比较大的压力。

**访问方式：**

业界有很多的方案可以屏蔽主从分离之后数据库访问的细节，让开发人员像是访问单一数据库一样，包括有像 TDDL、Sharding-JDBC 这样的嵌入应用内部的方案，也有像 Mycat 这样的独立部署的代理方案。

<img src="https://gitee.com/adambang/pic/raw/master/20210121170236.jpeg" alt="img" style="zoom:50%;" />

## 2.2 分库分表

### 2.2.1 MySQL分表

分表有两种分割方式，一种垂直拆分，另一种水平拆分。

- **垂直拆分**

  垂直分表，通常是按照业务功能的使用频次，把主要的、热门的字段放在一起做为主要表。然后把不常用的，按照各自的业务属性进行聚集，拆分到不同的次要表中；主要表和次要表的关系一般都是一对一的。

- **水平拆分(数据分片)**

  单表的容量不超过500W，否则建议水平拆分。是把一个表复制成同样表结构的不同表，然后把数据按照一定的规则划分，分别存储到这些表中，从而保证单表的容量不会太大，提升性能；当然这些结构一样的表，可以放在一个或多个数据库中。

  水平分割的几种方法：

- - 使用MD5哈希，做法是对UID进行md5加密，然后取前几位（我们这里取前两位），然后就可以将不同的UID哈希到不同的用户表（user_xx）中了。
  - 还可根据时间放入不同的表，比如：article_201601，article_201602。
  - 按热度拆分，高点击率的词条生成各自的一张表，低热度的词条都放在一张大表里，待低热度的词条达到一定的贴数后，再把低热度的表单独拆分成一张表。
  - 根据ID的值放入对应的表，第一个表user_0000，第二个100万的用户数据放在第二 个表user_0001中，随用户增加，直接添加用户表就行了。

### 2.2.2 MySQL分库

**为什么要分库?**

数据库集群环境后都是多台 slave，基本满足了读取操作;  但是写入或者说大数据、频繁的写入操作对master性能影响就比较大，这个时候，单库并不能解决大规模并发写入的问题，所以就会考虑分库。



一个库里表太多了，导致了海量数据，系统性能下降，把原本存储于一个库的表拆分存储到多个库上， 通常是将表按照功能模块、关系密切程度划分出来，部署到不同库上。

优点：

- 减少增量数据写入时的锁对查询的影响
- 由于单表数量下降，常见的查询操作由于减少了需要扫描的记录，使得单表单次查询所需的检索行数变少，减少了磁盘IO，时延变短

但是它无法解决单表数据量太大的问题

**分库分表后的难题**

分布式事务的问题，数据的完整性和一致性问题。

数据操作维度问题：用户、交易、订单各个不同的维度，用户查询维度、产品数据分析维度的不同对比分析角度。跨库联合查询的问题，可能需要两次查询 跨节点的count、order by、group by以及聚合函数问题，可能需要分别在各个节点上得到结果后在应用程序端进行合并 额外的数据管理负担，如：访问数据表的导航定位 额外的数据运算压力，如：需要在多个节点执行，然后再合并计算程序编码开发难度提升，没有太好的框架解决，更多依赖业务看如何分，如何合，是个难题。

# 三. 缓存

## 3.1 缓存概述

附一张缓存速度图如下：

![img](https://static001.geekbang.org/resource/image/01/ad/0134f4cd9e0d6e8d57ebe35eb28c32ad.jpg)

**缓存分类**

常见的缓存主要就是静态缓存、分布式缓存和热点本地缓存这三种。

静态缓存在 Web 1.0 时期是非常著名的，它一般通过生成 Velocity 模板或者静态 HTML 文件来实现静态缓存，在 Nginx 上部署静态缓存可以减少对于后台应用服务器的压力。

分布式缓存的大名可谓是如雷贯耳了，我们平时耳熟能详的 Memcached、Redis 就是分布式缓存的典型例子。它们性能强劲，通过一些分布式的方案组成集群可以突破单机的限制。

热点本地缓存主要部署在应用服务器的代码中，用于阻挡热点查询对于分布式缓存节点或者数据库的压力。

**缓存的不足**

1. 缓存比较适合于读多写少的业务场景，并且数据最好带有一定的热点属性。
2. 缓存会给整体系统带来复杂度，并且会有数据不一致的风险。
3. 缓存通常使用内存作为存储介质，但是内存并不是无限的。
4. 缓存会给运维也带来一定的成本

## 3.2 缓存使用

### 3.2.1 缓存的读写策略

**Cache Aside（旁路缓存）策略**

**Read/Write Through（读穿 / 写穿）策略**

**Write Back（写回）策略**

### 3.2.2 缓存的高可用

方案有客户端方案、中间代理层方案和服务端方案三大类：

- 客户端方案就是在客户端配置多个缓存的节点，通过缓存写入和读取算法策略来实现分布式，从而提高缓存的可用性。

  > 写入数据时，需要把被写入缓存的数据分散到多个节点中，即进行数据分片；
  >
  > 读数据时，可以利用多组的缓存来做容错，提升缓存系统的可用性。关于读数据，这里可以使用主从和多副本两种策略，两种策略是为了解决不同的问题而提出的。

- 中间代理层方案是在应用代码和缓存节点之间增加代理层，客户端所有的写入和读取的请求都通过代理层，而代理层中会内置高可用策略，帮助提升缓存系统的高可用。

- 服务端方案就是 Redis 2.4 版本后提出的 Redis Sentinel 方案。

# 四.消息队列

异步处理、解耦合和削峰填谷是消息队列在秒杀系统设计中起到的主要作用，其中异步处理可以简化业务流程中的步骤，提升系统性能；削峰填谷可以削去到达秒杀系统的峰值流量，让业务逻辑的处理更加缓和；解耦合可以将秒杀系统和数据系统解耦开，这样两个系统的任何变更都不会影响到另一个系统，

关于消息队列常见的问题：

https://github.com/unirabbit/javaNote/blob/master/md/%E4%B8%AD%E9%97%B4%E4%BB%B6/RocketMQ%E6%80%BB%E7%BB%93.md


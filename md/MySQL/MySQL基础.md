# Mysql基础 

## 基础架构

MySQL 的基本架构示意图如下：

<img src="https://gitee.com/adambang/pic/raw/master/20201110162214.png" alt="img" style="zoom: 25%;" />

大体来说，MySQL 可以分为 Server 层和存储引擎层两部分。

Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。

而存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎。

SQL语句的整体执行细节如下图：

<img src="https://gitee.com/adambang/pic/raw/master/20201110165708.png" alt="image-20201110165708521" style="zoom: 67%;" />

在SQL执行过程中，组件的作用如下：

1. **连接器**

第一步，你会先连接到这个数据库上，这时候接待你的就是连接器。连接器负责跟客户端建立连接、获取权限、维持和管理连接。

建立连接的过程通常是比较复杂的，所以建议在使用中要尽量减少建立连接的动作，也就是尽量使用*长连接*。但是全部使用长连接后，你可能会发现，有些时候 MySQL 占用内存涨得特别快，这是因为 MySQL 在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是 MySQL 异常重启了。

怎么解决这个问题呢？可以考虑以下两种方案。

- 定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。
- 如果用的是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。

2. **查询缓存**

连接建立完成后，就可以执行 select 语句了。执行逻辑就会来到第二步：查询缓存。之前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。(缓存查询弊大于利，容易失效)

3. **分析器**

如果没有命中查询缓存，就要开始真正执行语句了，MySQL需要对语句进行分析。

分析器先会做“词法分析”。你输入的是由多个字符串和空格组成的一条 SQL 语句，MySQL 需要识别出里面的字符串分别是什么，代表什么。MySQL 从你输入的"select"这个关键字识别出来，这是一个查询语句。它也要把字符串“T”识别成“表名 T”，把字符串“ID”识别成“列 ID”。

做完了这些识别以后，就要做“语法分析”。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。

4. **优化器**

经过了分析器，MySQL 就知道你要做什么了。在开始执行之前，还要先经过优化器的处理。优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。

5. **执行器**

MySQL 通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。

开始执行的时候，要先判断一下你对这个表 T 有没有执行查询的权限，如果没有，就会返回没有权限的错误，如下所示 (在工程实现上，如果命中查询缓存，会在查询缓存返回结果的时候，做权限验证。查询也会在优化器之前调用 precheck 验证权限)。

如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。

至此，这个语句就执行完成了。

## 存储引擎

存储引擎是 MySQL 中具体与文件打交道的子系统，它是根据 MySQL AB 公司提供的文件访问层抽象接口定制的一种文件访问机制，这种机制就叫作存储引擎，下面是一些常用的存储引擎，有远古时期的 MyISAM、支持事务的 InnoDB、内存类型的 Memory、归档类型的 Archive、列式存储的 Infobright，以及一些新兴的存储引擎。

 MyISAM索引文件和数据文件是分离的（非聚集）。

**区别：**

1. InnoDB 支持事务，MyISAM 不支持事务。这是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一；

2. InnoDB 支持外键，而 MyISAM 不支持。对一个包含外键的 InnoDB 表转为 MYISAM 会失败；  

3. InnoDB 是聚集索引，MyISAM 是非聚集索引。聚簇索引的文件存放在主键索引的叶子节点上，因此 InnoDB 必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。而 MyISAM 是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。 

4. InnoDB 不保存表的具体行数，执行 select count(*) from table 时需要全表扫描。而MyISAM 用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快；    

5. InnoDB 最小的锁粒度是行锁，MyISAM 最小的锁粒度是表锁。一个更新语句会锁住整张表，导致其他查询和更新都会被阻塞，因此并发访问受限。这也是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一；

**如何选择：**

1. 是否要支持事务，如果要请选择 InnoDB，如果不需要可以考虑 MyISAM；

2. 如果表中绝大多数都只是读查询，可以考虑 MyISAM，如果既有读写也挺频繁，请使用InnoDB。

3. 系统奔溃后，MyISAM恢复起来更困难，能否接受，不能接受就选 InnoDB；

4. MySQL5.5版本开始Innodb已经成为Mysql的默认引擎(之前是MyISAM)

## 日志系统

提交事务的时候，会把redo log日志写入磁盘文件中去。然后其实在提交事务的时 候，我们同时还会把这次更新对应的binlog日志写入到磁盘文件中去，如下图所示。



存储 引擎的基本日志系统（包括redolog和undolog）如下：

![image-20201130164951811](https://gitee.com/adambang/pic/raw/master/20201130164951.png)

### undo log

**作用：**

保存了事务发生之前的数据的一个版本，可以用于回滚，同时可以提供多版本并发控制下的读（MVCC），也即非锁定读。

主要分为两种：

1. insert undo log

> 代表事务在insert新记录时产生的undo log, 只在事务回滚时需要，并且在事务提交后可以被立即丢弃

1. update undo log

> 事务在进行update或delete时产生的undo log; 不仅在事务回滚时需要，在快照读时也需要；所以不能随便删除，只有在快速读或事务回滚不涉及该日志时，对应的日志才会被purge线程统一清除

### redo log

在更新完Buffer Pool中的缓存页之后，必须要写一条redo log，这样才能记录下来我们对数据库做的修改。
redo log可以保证我们事务提交之后，如果事务中的增删改SQL语句更新的缓存页还没刷到磁盘上去，此时MySQL宕机了，那么MySQL重启过后，就可以把redo log重做一遍，恢复出来事务当时更新的缓存页，然后再把缓存页刷到磁盘就可以了
redo log本质是保证事务提交之后，修改的数据绝对不会丢失的  

**作用：**

> 确保事务的持久性。防止在发生故障的时间点，尚有脏页未写入磁盘，在重启mysql服务的时候，根据redo log进行重做，从而达到事务的持久性这一特性。

在MySQL中如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程IO成本、查找成本都很高。而BinLog和RedoLog配合的整个过程就是MySQL用到的是Write-Ahead Logging 技术，它的关键点就是`先写日志，再写磁盘`。

> 1、 记录更新时，InnoDB引擎就会先把记录写到RedoLog里面，并更新内存。同时，InnoDB引擎会在空闲时将这个操作记录更新到磁盘里面。
>
> 2、 如果更新太多RedoLog处理不了的时候，需先将RedoLog部分数据写到磁盘，然后擦除RedoLog部分数据。RedoLog类似转盘。

RedoLog有`write pos` 跟`checkpoint`

> `write pos` ：是当前记录的位置，一边写一边后移，写到第3号文件末尾后就回到0号文件开头。
>
> `check point`：是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。

write pos和check point之间的是粉板上还空着的部分，可以用来记录新的操作。如果write pos追上checkpoint，表示粉板满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把checkpoint推进一下。

有了redo log，InnoDB就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为`crash-safe`。

<img src="https://gitee.com/adambang/pic/raw/master/20201210171018.png" alt="图片" style="zoom: 80%;" />

`redolog两阶段提交`：为了让binlog跟redolog两份日志之间的逻辑一致。提交流程大致如下：

> 1 写入redolog,prepare阶段 -->  2 写binlog  --> 3 redolog标记commit

1. 当在2之前崩溃时，重启恢复后发现没有commit，回滚。备份恢复：没有binlog 。一致
2. 当在3之前崩溃时，重启恢复发现虽没有commit，但满足prepare和binlog完整，所以重启后会`自动`commit。备份：有binlog一致

**binlog跟redolog区别**：

1. redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。
2. redo log是物理日志，记录的是在某个数据页上做了什么修改；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如给ID=2这一行的c字段加1。
3. redo log是循环写的，空间固定会用完；binlog是可以追加写入的。追加写是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。

### binlog(Server层日志)

binlog叫做归档日志，里面记录的是偏向于逻辑性的日志。`BinLog`是记录所有数据库表结构变更（例如create、alter table）以及表数据修改(insert、update、delete)的二进制日志。

**作用**：<u>只记录修改语句，用于数据库恢复和主从复制，默认关闭</u>

binLog日志文件有三种模式。

**STATEMENT 模式**

> `内容`：binlog 只会记录可能引起数据变更的 sql 语句
>
> `优势`：该模式下，因为没有记录实际的数据，所以日志量和 IO 都消耗很低，性能是最优的
>
> `劣势`：但有些操作并不是确定的，比如 uuid() 函数会随机产生唯一标识，当依赖 binlog 回放时，该操作生成的数据与原数据必然是不同的，此时可能造成无法预料的后果。

**ROW 模式**

> `内容`：在该模式下，binlog 会**记录每次操作的源数据与修改后的目标数据**，StreamSets就要求该模式。
>
> `优势`：可以绝对精准的还原，从而保证了数据的安全与可靠，并且复制和数据恢复过程可以是并发进行的
>
> `劣势`：缺点在于 binlog 体积会非常大，同时，对于修改记录多、字段长度大的操作来说，记录时性能消耗会很严重。阅读的时候也需要特殊指令来进行读取数据。

**MIXED 模式**

> `内容`：是对上述STATEMENT 跟 ROW  两种模式的混合使用。
>
> `细节`：对于绝大部分操作，都使用 STATEMENT 来进行 binlog 的记录，只有以下操作使用 ROW 来实现：表的存储引擎为 NDB，使用了uuid() 等不确定函数，使用了 insert delay 语句，使用了临时表

![图片](https://gitee.com/adambang/pic/raw/master/20201210170846.png)

**主从同步流程**：

> 1、主节点必须启用二进制日志，记录任何修改了数据库数据的事件。
>
> 2、从节点开启一个线程（I/O Thread)把自己扮演成 mysql 的客户端，通过 mysql 协议，请求主节点的二进制日志文件中的事件 。
>
> 3、主节点启动一个线程（dump Thread），检查自己二进制日志中的事件，跟对方请求的位置对比，如果不带请求位置参数，则主节点就会从第一个日志文件中的第一个事件一个一个发送给从节点。
>
> 4、从节点接收到主节点发送过来的数据把它放置到中继日志（Relay log）文件中。并记录该次请求到主节点的具体哪一个二进制日志文件内部的哪一个位置（主节点中的二进制文件会有多个）。
>
> 5、从节点启动另外一个线程（sql Thread ），把 Relay log 中的事件读取出来，并在本地再执行一次。

mysql默认的复制方式是`异步`的，并且复制的时候是有`并行复制能力`的。主库把日志发送给从库后不管了，这样会产生一个问题就是假设主库挂了，从库处理失败了，这时候从库升为主库后，**日志就丢失了**。由此产生两个概念。

1. 全同步复制

> 主库写入binlog后强制同步日志到从库，**所有的从库都执行完成后才返回给客户端**，但是很显然这个方式的话性能会受到严重影响。

1. 半同步复制

> 半同步复制的逻辑是这样，从库写入日志成功后返回`ACK`确认给主库，主库收到至少一个从库的确认就认为写操作完成。

### buffer pool

实际上假设我们要更新一行数据，此时数据库会找到这行数据所在的数据页，然后从磁盘文件里把这行数据所在的数据页直接给加载到Buffer Pool里去。

缓冲池的构造如下，磁盘文件的数据页和buffer pool的缓存页一一对应。

![image-20201130170204206](https://gitee.com/adambang/pic/raw/master/20201130170204.png)

**缓存页如何和数据页对应：**

实际上默认情况下，磁盘中存放的数据页的大小是16KB，也就是说，一页数据包含了16KB的内容。
而Buffer Pool中存放的一个一个的数据页，我们通常叫做缓存页，因为毕竟Buffer Pool是一个缓冲池，里面的数据都是从磁盘缓存到内存去的。
而Buffer Pool中默认情况下，一个缓存页的大小和磁盘上的一个数据页的大小是一一对应起来的，都是16KB。  

## 事务

### 事务特性

事务最基本的莫过于 ACID 四个特性了，这四个特性分别是：

**Atomicity：原子性**

事务被视为不可分割的最小单元，事务的所有操作要么全部成功，要么全部失败回滚。

**Consistency：一致性**

数据库在事务执行前后都保持一致性状态，在一致性状态下，所有事务对一个数据的读取结果都是相同的。

**Isolation：隔离性**

一个事务所做的修改在最终提交以前，对其他事务是不可见的。

**Durability：持久性**

一旦事务提交，则其所做的修改将会永远保存到数据库中。即使系统发生崩溃，事务执行的结果也不能丢。

事务的 ACID 特性概念很简单，但不好理解，主要是因为这几个特性不是一种平级关系：

- 只有满足一致性，事务的结果才是正确的。
- 在无并发的情况下，事务串行执行，隔离性一定能够满足。此时只要能满足原子性，就一定能满足一致性。在并发的情况下，多个事务并行执行，事务不仅要满足原子性，还需要满足隔离性，才能满足一致性。
- 事务满足持久化是为了能应对数据库崩溃的情况。

<img src="https://mmbiz.qpic.cn/mmbiz_jpg/uChmeeX1FpwqHyYbEIPyeesNicgZ2s5NTGYL30g0TKLx51l4f5Hs9DUzWicjAgDLrJWse8Aia81kxtuJic5OXIrwBQ/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="img" style="zoom: 50%;" />

### 事务隔离级别

**未提交读（READ UNCOMMITTED）**

事务中的修改，即使没有提交，对其他事务也是可见的。

**提交读（READ COMMITTED）**

一个事务只能读取已经提交的事务所做的修改。换句话说，一个事务所做的修改在提交之前对其他事务是不可见的。

**可重复读（REPEATABLE READ）**

保证在同一个事务中多次读取同样数据的结果是一样的。

**可串行化（SERIALIZABLE）**

强制事务串行执行。



**事务问题**

脏读（读未提交）：一个事务读取到另外一个事务还没有提交的数据

不可重复读（读提交）：在同一个事务内，两次相同的查询返回了不同的结果（修改）

幻读（可重复读）：同一个事务内多次查询返回的结果集不一样（新增/删除）

**幻读和不可重复读的区别：**

- **不可重复读的重点是修改**：在同一事务中，同样的条件，第一次读的数据和第二次读的数据不一样。（因为中间有其他事务提交了修改）
- **幻读的重点在于新增或者删除**：在同一事务中，同样的条件,，第一次和第二次读出来的记录数不一样。（因为中间有其他事务提交了插入/删除）

### MVCC原理

MVCC：

> 1、全称`Multi-Version Concurrency Control`，即`多版本并发控制`。MVCC是一种并发控制的`理念`，维持一个数据的多个版本，使得读写操作没有冲突。
>
> 2、MVCC在MySQL InnoDB中实现目的主要是为了**提高数据库并发性能**，用更好的方式去处理读-写冲突，做到即使有读写冲突时，也能做到不加锁，非阻塞并发读。

MySQL的RR隔离级别可通过MVCC避免幻读。MySQL实现MVCC机制的时候，是基于undo log多版本链条+ReadView机制的。

MVCC实现原理主要是依赖记录中的 `四个隐式字段`、`undo日志` 、`Consistent Read View`来实现的。

**四个隐式字段**：

> DB_TRX_ID：
>
> > 6byte，最近修改(修改/插入)事务ID：记录创建这条记录/最后一次修改该记录的`事务ID`
>
> DB_ROLL_PTR
>
> > 7byte，回滚指针，指向这条记录的`上一个版本`（存储于rollback segment里）
>
> DB_ROW_ID
>
> > 6byte，隐含的自增ID（`隐藏主键`），如果数据表没有主键，InnoDB会自动以DB_ROW_ID产生一个聚簇索引
>
> FLAG
>
> > 一个删除flag隐藏字段, 既记录被更新或删除并不代表真的删除，而是删除flag变了

执行一个事务的时候，就给你生成一个**ReadView** ，里面比较关键的东西有4个

- m_ids，这个就是说此时有哪些事务在MySQL里执行还没提交的；
- min_trx_id，就是m_ids里最小的值；
- max_trx_id，这是说mysql下一个要生成的事务id，就是最大事务id；
- creator_trx_id，就是本事务的id  

**MySQL InnoDB下的当前读和快照读**

1. 当前读

> 1、像`select lock in share mode`(共享锁)、`select for update` 、`update`、`insert`、`delete`(排他锁)这些操作都是一种`当前读`，就是它读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对`读取的记录进行加锁`。
>
> 2、当前读可以认为是`悲观锁`的具体功能实现

2. 快照读

> 1、不加锁的select就是快照读，即不加锁的非阻塞读；快照读的前提是隔离级别不是串行级别，串行级别下的快照读会退化成当前读；之所以出现快照读的情况，是基于提高并发性能的考虑，快照读的实现是基于多版本并发控制，即`MVCC`，可以认为`MVCC是行锁的一个变种`，但它在很多情况下，`避免了加锁操作`，降低了开销；既然是基于多版本，即快照读可能读到的并不一定是数据的最新版本，而有可能是之前的历史版本。
>
> 2、快照读就是MVCC思想在MySQL的具体非阻塞读功能实现，MVCC的目的就是为了实现读-写冲突不加锁，提高并发读写性能，而这个读指的就是`快照读`。
>
> 3、快照读就是MySQL为我们实现MVCC理想模型的其中一个具体非阻塞读功能。

`重点`：

> 1、事务中快照读的结果是`非常依赖`该事务首次出现快照读的地方，即某个事务中首次出现快照读的地方非常关键，它有决定该事务后续快照读结果的能力。
>
> 2、在`RC`隔离级别下，是每个快照读`都会生成`并获取最新的Read View；而在`RR`隔离级别下，则是同一个事务中的`第一个`快照读才会创建Read View, 之后的快照读获取的都是`同一个`Read View。

### MVCC下的事务

ReadView机制，是基于undo log版本链条实现的一套读视图机制。当前事务生成一个ReadView，当前事务自己更新的数据可以读到的，或者是生成ReadView之前提交的事务修改的值，也是可以读取到的。  

**RC**

RC是每次读取都生成一个新的readview，保证整个事务中读到其他修改提交后的最新值 。

**RR**

RR是整个事务中生成一个readview，第一次查询就会生成一个ReadView。对自己查询的部分添加间隙锁，防止被插入删除。

> **幻读**：在InnoDB的可重复度隔离级别下，使用当前读，一个事务前后两次查询同一个范围，后一次查询会看到期间新插入的行；
>
> **幻读的影响**：会导致一个事务中先产生的锁，无法锁住后加入的行，会产生数据一致性问题；
>
> **产生幻读的原因**：行锁只能锁住一行，不能避免新插入的记录；
>
> **解决幻读**：在两行记录之间加上间隙锁，阻止新纪录的插入，与间隙锁产生冲突的只有“往这个间隙插入记录”这个操作；
>
> 同时添加间隙锁与行锁称为**Next-key lock**，注意`间隙锁只有在InnoDB的可重复读隔离级别下生效`；
>
> MVCC只实现读取已提交和可重复读，InnoDB在可重复度的隔离级别下，使用MVCC+Next-key lock解决幻读

当使用唯一索引来搜索唯一行的语句时，不需要间隙锁定

## 锁

根据加锁的范围，MySQL 里面的锁大致可以分成全局锁、表级锁和行锁三类。

### 全局锁

顾名思义，全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。

**全局锁的典型使用场景是，做全库逻辑备份。**不加锁的情况：在可重复读隔离级别下开启一个事务，获取一致性视图。

风险

- 如果在主库备份，在备份期间不能更新，业务停摆
- 如果在从库备份，备份期间不能执行主库同步的binlog，导致主从延迟

### 表级锁

MySQL 里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。

**表锁**

- 表锁的语法是 lock tables … read/write
- 可以用unlock tables主动释放锁，也可以在客户端断开时自动释放

**元数据锁（MDL)**

- MDL 不需要显式使用，在访问一个表的时候会被自动加上，保证读写的正确性
- 当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。
- 读读不互斥，读写/写写互斥

### 行锁

MySQL 的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如 MyISAM 引擎就不支持行锁。

在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时(提交)才释放。这个就是**两阶段锁协议**。

> 如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。

InnoDB下行锁可细分为记录锁（Record Lock）、间隙锁（Gap Lock)、临键锁（Next_Key Lock），是基于索引实现的，其本质上是三种加锁算法。

#### 记录锁（Record Locks）

顾名思义，记录锁就是为某行记录加锁，它`封锁该行的索引记录`。<u>宏观意义上的行锁就是记录锁</u>：

```
-- id 列为主键列或唯一索引列``SELECT` `* ``FROM` `table` `WHERE` `id = 1 ``FOR` `UPDATE``;　　
```

id 为 1 的记录行会被锁住。

需要注意的是：`id` 列必须为`唯一索引列`或`主键列`，否则上述语句加的锁就会变成`临键锁`。

同时查询语句必须为`精准匹配`（`=`），不能为 `>`、`<`、`like`等，否则也会退化成`临键锁`。

**其他实现**

在通过 `主键索引` 与 `唯一索引` 对数据行进行 UPDATE 操作时，也会对该行数据加`记录锁`：

```
-- id 列为主键列或唯一索引列``UPDATE` `SET` `age = 50 ``WHERE` `id = 1;
```

#### 间隙锁（Gap Locks）

间隙锁基于`非唯一索引`，它`锁定一段范围内的索引记录`。间隙锁基于下面将会提到的`Next-Key Locking` 算法，请务必牢记：使用间隙锁锁住的是一个区间，而不仅仅是这个区间中的每一条数据。

```
SELECT` `* ``FROM` `table` `WHERE` `id BETWEN 1 ``AND` `10 ``FOR` `UPDATE``;
```

即所有在`（1，10）`区间内的记录行都会被锁住，所有id 为 2、3、4、5、6、7、8、9 的数据行的插入会被阻塞，但是 1 和 10 两条记录行并不会被锁住。

除了手动加锁外，在执行完某些 SQL 后，InnoDB 也会自动加间隙锁，这个我们在下面会提到。

#### 临键锁（Next-Key Locks）

记录锁与间隙锁组合起来用就叫做Next-Key Lock，就是将键及其两边的的间隙加锁（向左扫描扫到第一个比给定参数小的值， 向右扫描扫描到第一个比给定参数大的值， 然后以此为界，构建一个区间）。

Next-Key 可以理解为一种特殊的间隙锁，也可以理解为一种特殊的算法。通过临建锁可以解决`幻读`的问题。 每个数据行上的`非唯一索引列`上都会存在一把临键锁，当某个事务持有该数据行的临键锁时，会锁住一段左开右闭区间的数据。需要强调的一点是，`InnoDB` 中`行级锁`是基于索引实现的，临键锁只与`非唯一索引列`有关，在`唯一索引列`（包括`主键列`）上不存在临键锁。

### 死锁和死锁检测

当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为**死锁**。

当出现死锁以后，有两种策略：

- 一种策略是，直接进入**等待**，直到**超时**。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。

- 另一种策略是，发起**死锁检测**，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。

  超时时间设置过长影响业务，设置过短锁失去意义。

  死锁检测每个加锁的事务都要进行死锁判断，要耗费大量的 CPU 资源。

  解决方法：  

  1. 能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。（可能造成超时，业务有损）

  2. 控制并发度

## 索引

MySQL官方对索引的定义为：索引(Index)是帮助MySQL高效获取数据的数据结构。

### 索引分类

**结构**

B+树索引

Hash索引

全文索引

R-Tree 索引

类型

- 单值索引

- 唯一索引

- 复合索引

  - 覆盖索引

    查询的列刚好与创建的索引列的列名及顺序全部匹配或者部分匹配

### 索引结构

**索引（index）是在存储引擎（storage engine）层面实现的，而不是server层面**。不是所有的存储引擎都支持所有的索引类型。即使多个存储引擎支持某一索引类型，它们的实现和行为也可能有所差别。

#### B+Tree索引

MyISAM 和 InnoDB 存储引擎，都使用 B+Tree的数据结构，它相对与 B-Tree结构，所有的数据都存放在叶子节点上，且把叶子节点通过指针连接到一起，形成了一条数据链表，以加快相邻数据的检索效率。

##### 结构演进

二叉查找树

- 查找耗时与树的深度相关的，最坏时间复杂度会退化成O(n)

平衡二叉树

- 左右子树深度差绝对值不能超过 1
- 插入/删除节点，需要频繁调整树结构，性能较差
- 树的深度过深，磁盘IO开销较大

红黑树

- 叶子节点全黑，一红带两黑，弱平衡性
- 适用于删除插入操作较多的情况

B树

- 叶子节点，非叶子节点，都存储数据
- 中序遍历，可以获得所有节点

B+树

- 非叶子节点不再存储数据，数据只存储在同一层的叶子节点上
- 叶子之间，增加了链表，获取所有节点，不再需要中序遍历

##### 存储原理

在计算机中磁盘存储数据最小单元是扇区，一个扇区的大小是 512 字节，而文件系统（例如XFS/EXT4）他的最小单元是块，一个块的大小是 4k，而对于 InnoDB 存储引擎也有自己的最小储存单元——页（Page），一个页的大小是 16K。

> InnoDB 存储引擎中有页（Page）的概念，页是其磁盘管理的最小单位。InnoDB 存储引擎中默认每个页的大小为16KB，可通过参数 `innodb_page_size` 将页的大小设置为 4K、8K、16K，在 MySQL 中可通过如下命令查看页的大小：`show variables like 'innodb_page_size';`

一页对应B+树内的一个节点，假设一行数据的大小是 1k，那么一个页可以存放 16 行这样的数据。同时数据页内会有指向其它页的指针。

![img](https://gitee.com/adambang/pic/raw/master/20201225095434.jpeg)

##### 内部组成

**B Tree**

B-Tree 中的每个节点根据实际情况可以包含大量的关键字信息和分支，如下图所示为一个 3 阶的 B-Tree：

![图片](https://gitee.com/adambang/pic/raw/master/20201225100857.png)

每个节点占用一个盘块的磁盘空间，一个节点上有两个升序排序的关键字和三个指向子树根节点的指针，指针存储的是子节点所在磁盘块的地址。两个关键词划分成的三个范围域对应三个指针指向的子树的数据的范围域。以根节点为例，关键字为17和35，P1指针指向的子树的数据范围为小于17，P2指针指向的子树的数据范围为17~35，P3指针指向的子树的数据范围为大于35。

模拟查找关键字29的过程：

> 1. 根据根节点找到磁盘块1，读入内存。【磁盘I/O操作第1次】
> 2. 比较关键字29在区间（17,35），找到磁盘块1的指针P2。
> 3. 根据P2指针找到磁盘块3，读入内存。【磁盘I/O操作第2次】
> 4. 比较关键字29在区间（26,30），找到磁盘块3的指针P2。
> 5. 根据P2指针找到磁盘块8，读入内存。【磁盘I/O操作第3次】
> 6. 在磁盘块8中的关键字列表中找到关键字29。

分析上面过程，发现需要3次磁盘I/O操作，和3次内存查找操作。由于内存中的关键字是一个有序表结构，可以利用二分法查找提高效率。而3次磁盘I/O操作是影响整个B-Tree查找效率的决定因素。B-Tree相对于AVLTree缩减了节点个数，使每次磁盘I/O取到内存的数据都发挥了作用，从而提高了查询效率。

**B+ 树**

B+Tree 是在 B-Tree 基础上的一种优化，使其更适合实现外存储索引结构，InnoDB 存储引擎就是用 B+Tree 实现其索引结构。

从上一节中的B-Tree结构图中可以看到每个节点中不仅包含数据的key值，还有data值。而每一个页的存储空间是有限的，如果data数据较大时将会导致每个节点（即一个页）能存储的key的数量很小，当存储的数据量很大时同样会导致B-Tree的深度较大，增大查询时的磁盘I/O次数，进而影响查询效率。在B+Tree中，**所有数据记录节点都是按照键值大小顺序存放在同一层的叶子节点上**，而非叶子节点上只存储key值信息，这样可以大大加大每个节点存储的key值数量，降低B+Tree的高度。

B+Tree相对于B-Tree有几点不同：

> 1. 非叶子节点只存储键值信息；
> 2. 所有叶子节点之间都有一个链指针；
> 3. 数据记录都存放在叶子节点中

将上一节中的B-Tree优化，由于B+Tree的非叶子节点只存储键值信息，假设每个磁盘块能存储4个键值及指针信息，则变成B+Tree后其结构如下图所示：

![图片](https://gitee.com/adambang/pic/raw/master/20201225101234.webp)

通常在B+Tree上有两个头指针，一个指向根节点，另一个指向关键字最小的叶子节点，而且所有叶子节点（即数据节点）之间是一种链式环结构。因此可以对B+Tree进行两种查找运算：一种是对于主键的范围查找和分页查找，另一种是从根节点开始，进行随机查找。

可能上面例子中只有22条数据记录，看不出B+Tree的优点，下面做一个推算：

InnoDB存储引擎中页的大小为16KB，一般表的主键类型为INT（占用4个字节）或BIGINT（占用8个字节），指针类型也一般为4或8个字节，也就是说一个页（B+Tree中的一个节点）中大概存储16KB/(8B+8B)=1K个键值（因为是估值，为方便计算，这里的K取值为10^3）。也就是说一个深度为3的B+Tree索引可以维护10^3 * 10^3 * 10^3 = 10亿 条记录。

实际情况中每个节点可能不能填充满，因此在数据库中，B+Tree的高度一般都在2-4层。MySQL的InnoDB存储引擎在设计时是将根节点常驻内存的，也就是说查找某一键值的行记录时最多只需要1~3次磁盘I/O操作。

#### Hash索引

主要就是通过Hash算法（常见的Hash算法有直接定址法、平方取中法、折叠法、除数取余法、随机数法），将数据库字段数据转换成定长的Hash值，与这条数据的行指针一并存入Hash表的对应位置；如果发生Hash碰撞（两个不同关键字的Hash值相同），则在对应Hash键下以链表形式存储。

检索算法：在检索查询时，就再次对待查关键字再次执行相同的Hash算法，得到Hash值，到对应Hash表对应位置取出数据即可，如果发生Hash碰撞，则需要在取值时进行筛选。目前使用Hash索引的数据库并不多，主要有Memory等。

MySQL目前有**Memory**引擎和NDB引擎支持Hash索引

#### full-text全文索引

- 全文索引也是MyISAM的一种特殊索引类型，主要用于全文索引，InnoDB从MYSQL5.6版本提供对全文索引的支持。
- 它用于替代效率较低的LIKE模糊匹配操作，而且可以通过多字段组合的全文索引一次性全模糊匹配多个字段。
- 同样使用B-Tree存放索引数据，但使用的是特定的算法，将字段数据分割后再进行索引（一般每4个字节一次分割），索引文件存储的是分割前的索引字符串集合，与分割后的索引信息，对应Btree结构的节点存储的是分割后的词信息以及它在分割前的索引字符串集合中的位置。

#### R-Tree空间索引

空间索引是MyISAM的一种特殊索引类型，主要用于地理空间数据类型

### 索引场景

#### **哪些情况需要创建索引**

1. 主键自动建立唯一索引

2. 频繁作为查询的条件的字段应该创建索引

3. 查询中与其他表关联的字段，外键关系建立索引

4. 频繁更新的字段不适合创建索引

   因为每次更新不单单是更新了记录还会更新索引，加重IO负担

5. Where条件里用不到的字段不创建索引

6. 单一索引/复合索引的选择问题，平时选择哪一个？who？（在高并发下倾向创建组合索引）

7. 查询中排序（order by）的字段，排序字段若通过索引去访问将大大提高排序的速度

   比如你创建复合索引（name,age,address），那么排序的时候如果还按照name,age,address排序，速度会非常快。

8. 查询中统计或者分组（group by）字段

#### **哪些情况不要创建索引**

1. 表记录太少

   mysql虽然官方说能撑得住500到800万，但是实际上，300万条数据，性能就开始下降。

2. 经常增删改的表

3. 数据重复且分布平均的表字段，因此应该只为经常查询和经常排序的数据列建立索引。 

   比如国籍，省市县，男女，这样的数据重复率高，这样的就不适合建索引。

   注意，如果某个数据列包含许多重复的内容，为它建立索引就没有太大的实际效果。

#### MySQL高效索引

**覆盖索引**（Covering Index）,或者叫索引覆盖， 也就是平时所说的不需要回表操作

- 就是select的数据列只用从索引中就能够取得，不必读取数据行，MySQL可以利用索引返回select列表中的字段，而不必根据索引再次读取数据文件，换句话说**查询列要被所建的索引覆盖**。

- 索引是高效找到行的一个方法，但是一般数据库也能使用索引找到一个列的数据，因此它不必读取整个行。毕竟索引叶子节点存储了它们索引的数据，当能通过读取索引就可以得到想要的数据，那就不需要读取行了。一个索引包含（覆盖）满足查询结果的数据就叫做覆盖索引。

- **判断标准**

  使用explain，可以通过输出的extra列来判断，对于一个索引覆盖查询，显示为**using index**，MySQL查询优化器在执行查询前会决定是否有索引覆盖查询

#### MySQL中 in和 exists 的区别？

- exists：exists对外表用loop逐条查询，每次查询都会查看exists的条件语句，当exists里的条件语句能够返回记录行时（无论记录行是的多少，只要能返回），条件就为真，返回当前loop到的这条记录；反之，如果exists里的条件语句不能返回记录行，则当前loop到的这条记录被丢弃，exists的条件就像一个bool条件，当能返回结果集则为true，不能返回结果集则为false
- in：in查询相当于多个or条件的叠加

```
SELECT * FROM A WHERE A.id IN (SELECT id FROM B);
SELECT * FROM A WHERE EXISTS (SELECT * from B WHERE B.id = A.id);
```

**如果查询的两个表大小相当，那么用in和exists差别不大**。

如果两个表中一个较小，一个是大表，则子查询表大的用exists，子查询表小的用in.

## 大数据量

### MySQL分表

分表有两种分割方式，一种垂直拆分，另一种水平拆分。

- **垂直拆分**

  垂直分表，通常是按照业务功能的使用频次，把主要的、热门的字段放在一起做为主要表。然后把不常用的，按照各自的业务属性进行聚集，拆分到不同的次要表中；主要表和次要表的关系一般都是一对一的。

- **水平拆分(数据分片)**

  单表的容量不超过500W，否则建议水平拆分。是把一个表复制成同样表结构的不同表，然后把数据按照一定的规则划分，分别存储到这些表中，从而保证单表的容量不会太大，提升性能；当然这些结构一样的表，可以放在一个或多个数据库中。

  水平分割的几种方法：

- - 使用MD5哈希，做法是对UID进行md5加密，然后取前几位（我们这里取前两位），然后就可以将不同的UID哈希到不同的用户表（user_xx）中了。
  - 还可根据时间放入不同的表，比如：article_201601，article_201602。
  - 按热度拆分，高点击率的词条生成各自的一张表，低热度的词条都放在一张大表里，待低热度的词条达到一定的贴数后，再把低热度的表单独拆分成一张表。
  - 根据ID的值放入对应的表，第一个表user_0000，第二个100万的用户数据放在第二 个表user_0001中，随用户增加，直接添加用户表就行了。

### MySQL分库

**为什么要分库?**

数据库集群环境后都是多台 slave，基本满足了读取操作;  但是写入或者说大数据、频繁的写入操作对master性能影响就比较大，这个时候，单库并不能解决大规模并发写入的问题，所以就会考虑分库。



一个库里表太多了，导致了海量数据，系统性能下降，把原本存储于一个库的表拆分存储到多个库上， 通常是将表按照功能模块、关系密切程度划分出来，部署到不同库上。

优点：

- 减少增量数据写入时的锁对查询的影响
- 由于单表数量下降，常见的查询操作由于减少了需要扫描的记录，使得单表单次查询所需的检索行数变少，减少了磁盘IO，时延变短

但是它无法解决单表数据量太大的问题

**分库分表后的难题**

分布式事务的问题，数据的完整性和一致性问题。

数据操作维度问题：用户、交易、订单各个不同的维度，用户查询维度、产品数据分析维度的不同对比分析角度。跨库联合查询的问题，可能需要两次查询 跨节点的count、order by、group by以及聚合函数问题，可能需要分别在各个节点上得到结果后在应用程序端进行合并 额外的数据管理负担，如：访问数据表的导航定位 额外的数据运算压力，如：需要在多个节点执行，然后再合并计算程序编码开发难度提升，没有太好的框架解决，更多依赖业务看如何分，如何合，是个难题。

### 主从同步

首先先了解mysql主从同步的原理

1. master提交完事务后，写入binlog
2. slave连接到master，获取binlog
3. master创建dump线程，推送binglog到slave
4. slave启动一个IO线程读取同步过来的master的binlog，记录到relay log中继日志中
5. slave再开启一个sql线程读取relay log事件并在slave执行，完成同步
6. slave记录自己的binglog

<img src="https://gitee.com/adambang/pic/raw/master/20201225104715.jpeg" alt="img" style="zoom:50%;" />

由于mysql默认的复制方式是异步的，主库把日志发送给从库后不关心从库是否已经处理，这样会产生一个问题就是假设主库挂了，从库处理失败了，这时候从库升为主库后，日志就丢失了。由此产生两个概念。

**全同步复制**

主库写入binlog后强制同步日志到从库，所有的从库都执行完成后才返回给客户端，但是很显然这个方式的话性能会受到严重影响。

**半同步复制**

和全同步不同的是，半同步复制的逻辑是这样，从库写入日志成功后返回ACK确认给主库，主库收到至少一个从库的确认就认为写操作完成。
# Mysql基础 

## 基础架构

MySQL 的基本架构示意图如下：

<img src="https://gitee.com/adambang/pic/raw/master/20201110162214.png" alt="img" style="zoom: 25%;" />

大体来说，MySQL 可以分为 Server 层和存储引擎层两部分。

Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。

而存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎。

SQL语句的整体执行细节如下图：

<img src="https://gitee.com/adambang/pic/raw/master/20201110165708.png" alt="image-20201110165708521" style="zoom: 67%;" />

在SQL执行过程中，组件的作用如下：

1. **连接器**

第一步，你会先连接到这个数据库上，这时候接待你的就是连接器。连接器负责跟客户端建立连接、获取权限、维持和管理连接。

建立连接的过程通常是比较复杂的，所以建议在使用中要尽量减少建立连接的动作，也就是尽量使用*长连接*。但是全部使用长连接后，你可能会发现，有些时候 MySQL 占用内存涨得特别快，这是因为 MySQL 在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是 MySQL 异常重启了。

怎么解决这个问题呢？可以考虑以下两种方案。

- 定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。
- 如果用的是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。

2. **查询缓存**

连接建立完成后，就可以执行 select 语句了。执行逻辑就会来到第二步：查询缓存。之前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。(缓存查询弊大于利，容易失效)

3. **分析器**

如果没有命中查询缓存，就要开始真正执行语句了，MySQL需要对语句进行分析。

分析器先会做“词法分析”。你输入的是由多个字符串和空格组成的一条 SQL 语句，MySQL 需要识别出里面的字符串分别是什么，代表什么。MySQL 从你输入的"select"这个关键字识别出来，这是一个查询语句。它也要把字符串“T”识别成“表名 T”，把字符串“ID”识别成“列 ID”。

做完了这些识别以后，就要做“语法分析”。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。

4. **优化器**

经过了分析器，MySQL 就知道你要做什么了。在开始执行之前，还要先经过优化器的处理。优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。

5. **执行器**

MySQL 通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。

开始执行的时候，要先判断一下你对这个表 T 有没有执行查询的权限，如果没有，就会返回没有权限的错误，如下所示 (在工程实现上，如果命中查询缓存，会在查询缓存返回结果的时候，做权限验证。查询也会在优化器之前调用 precheck 验证权限)。

如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。

至此，这个语句就执行完成了。

## 存储引擎

存储引擎是 MySQL 中具体与文件打交道的子系统，它是根据 MySQL AB 公司提供的文件访问层抽象接口定制的一种文件访问机制，这种机制就叫作存储引擎，下面是一些常用的存储引擎，有远古时期的 MyISAM、支持事务的 InnoDB、内存类型的 Memory、归档类型的 Archive、列式存储的 Infobright，以及一些新兴的存储引擎。

 MyISAM索引文件和数据文件是分离的（非聚集）。

**区别：**

1. InnoDB 支持事务，MyISAM 不支持事务。这是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一；

2. InnoDB 支持外键，而 MyISAM 不支持。对一个包含外键的 InnoDB 表转为 MYISAM 会失败；  

3. InnoDB 是聚集索引，MyISAM 是非聚集索引。聚簇索引的文件存放在主键索引的叶子节点上，因此 InnoDB 必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。而 MyISAM 是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。 

4. InnoDB 不保存表的具体行数，执行 select count(*) from table 时需要全表扫描。而MyISAM 用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快；    

5. InnoDB 最小的锁粒度是行锁，MyISAM 最小的锁粒度是表锁。一个更新语句会锁住整张表，导致其他查询和更新都会被阻塞，因此并发访问受限。这也是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一；

**如何选择：**

1. 是否要支持事务，如果要请选择 InnoDB，如果不需要可以考虑 MyISAM；

2. 如果表中绝大多数都只是读查询，可以考虑 MyISAM，如果既有读写也挺频繁，请使用InnoDB。

3. 系统奔溃后，MyISAM恢复起来更困难，能否接受，不能接受就选 InnoDB；

4. MySQL5.5版本开始Innodb已经成为Mysql的默认引擎(之前是MyISAM)

## 日志系统

提交事务的时候，会把redo log日志写入磁盘文件中去。然后其实在提交事务的时 候，我们同时还会把这次更新对应的binlog日志写入到磁盘文件中去，如下图所示。



存储 引擎的基本日志系统（包括redolog和undolog）如下：

![image-20201130164951811](https://gitee.com/adambang/pic/raw/master/20201130164951.png)

### undo log

**作用：**

保存了事务发生之前的数据的一个版本，可以用于回滚，同时可以提供多版本并发控制下的读（MVCC），也即非锁定读。

主要分为两种：

1. insert undo log

> 代表事务在insert新记录时产生的undo log, 只在事务回滚时需要，并且在事务提交后可以被立即丢弃

1. update undo log

> 事务在进行update或delete时产生的undo log; 不仅在事务回滚时需要，在快照读时也需要；所以不能随便删除，只有在快速读或事务回滚不涉及该日志时，对应的日志才会被purge线程统一清除

### redo log

在更新完Buffer Pool中的缓存页之后，必须要写一条redo log，这样才能记录下来我们对数据库做的修改。
redo log可以保证我们事务提交之后，如果事务中的增删改SQL语句更新的缓存页还没刷到磁盘上去，此时MySQL宕机了，那么MySQL重启过后，就可以把redo log重做一遍，恢复出来事务当时更新的缓存页，然后再把缓存页刷到磁盘就可以了
redo log本质是保证事务提交之后，修改的数据绝对不会丢失的  

**作用：**

> 确保事务的持久性。防止在发生故障的时间点，尚有脏页未写入磁盘，在重启mysql服务的时候，根据redo log进行重做，从而达到事务的持久性这一特性。

在MySQL中如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程IO成本、查找成本都很高。而BinLog和RedoLog配合的整个过程就是MySQL用到的是Write-Ahead Logging 技术，它的关键点就是`先写日志，再写磁盘`。

> 1、 记录更新时，InnoDB引擎就会先把记录写到RedoLog里面，并更新内存。同时，InnoDB引擎会在空闲时将这个操作记录更新到磁盘里面。
>
> 2、 如果更新太多RedoLog处理不了的时候，需先将RedoLog部分数据写到磁盘，然后擦除RedoLog部分数据。RedoLog类似转盘。

RedoLog有`write pos` 跟`checkpoint`

> `write pos` ：是当前记录的位置，一边写一边后移，写到第3号文件末尾后就回到0号文件开头。
>
> `check point`：是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。

write pos和check point之间的是粉板上还空着的部分，可以用来记录新的操作。如果write pos追上checkpoint，表示粉板满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把checkpoint推进一下。

有了redo log，InnoDB就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为`crash-safe`。

<img src="https://gitee.com/adambang/pic/raw/master/20201210171018.png" alt="图片" style="zoom: 80%;" />

`redolog两阶段提交`：为了让binlog跟redolog两份日志之间的逻辑一致。提交流程大致如下：

> 1 prepare阶段 -->  2 写binlog  --> 3 commit

1. 当在2之前崩溃时，重启恢复后发现没有commit，回滚。备份恢复：没有binlog 。一致
2. 当在3之前崩溃时，重启恢复发现虽没有commit，但满足prepare和binlog完整，所以重启后会`自动`commit。备份：有binlog一致

**binlog跟redolog区别**：

1. redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。
2. redo log是物理日志，记录的是在某个数据页上做了什么修改；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如给ID=2这一行的c字段加1。
3. redo log是循环写的，空间固定会用完；binlog是可以追加写入的。追加写是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。

### binlog(Server层日志)

binlog叫做归档日志，里面记录的是偏向于逻辑性的日志。`BinLog`是记录所有数据库表结构变更（例如create、alter table）以及表数据修改(insert、update、delete)的二进制日志。

**作用**：<u>只记录修改语句，用于数据库恢复和主从复制，默认关闭</u>

binLog日志文件有三种模式。

**STATEMENT 模式**

> `内容`：binlog 只会记录可能引起数据变更的 sql 语句
>
> `优势`：该模式下，因为没有记录实际的数据，所以日志量和 IO 都消耗很低，性能是最优的
>
> `劣势`：但有些操作并不是确定的，比如 uuid() 函数会随机产生唯一标识，当依赖 binlog 回放时，该操作生成的数据与原数据必然是不同的，此时可能造成无法预料的后果。

**ROW 模式**

> `内容`：在该模式下，binlog 会**记录每次操作的源数据与修改后的目标数据**，StreamSets就要求该模式。
>
> `优势`：可以绝对精准的还原，从而保证了数据的安全与可靠，并且复制和数据恢复过程可以是并发进行的
>
> `劣势`：缺点在于 binlog 体积会非常大，同时，对于修改记录多、字段长度大的操作来说，记录时性能消耗会很严重。阅读的时候也需要特殊指令来进行读取数据。

**MIXED 模式**

> `内容`：是对上述STATEMENT 跟 ROW  两种模式的混合使用。
>
> `细节`：对于绝大部分操作，都使用 STATEMENT 来进行 binlog 的记录，只有以下操作使用 ROW 来实现：表的存储引擎为 NDB，使用了uuid() 等不确定函数，使用了 insert delay 语句，使用了临时表

![图片](https://gitee.com/adambang/pic/raw/master/20201210170846.png)

**主从同步流程**：

> 1、主节点必须启用二进制日志，记录任何修改了数据库数据的事件。
>
> 2、从节点开启一个线程（I/O Thread)把自己扮演成 mysql 的客户端，通过 mysql 协议，请求主节点的二进制日志文件中的事件 。
>
> 3、主节点启动一个线程（dump Thread），检查自己二进制日志中的事件，跟对方请求的位置对比，如果不带请求位置参数，则主节点就会从第一个日志文件中的第一个事件一个一个发送给从节点。
>
> 4、从节点接收到主节点发送过来的数据把它放置到中继日志（Relay log）文件中。并记录该次请求到主节点的具体哪一个二进制日志文件内部的哪一个位置（主节点中的二进制文件会有多个）。
>
> 5、从节点启动另外一个线程（sql Thread ），把 Relay log 中的事件读取出来，并在本地再执行一次。

mysql默认的复制方式是`异步`的，并且复制的时候是有`并行复制能力`的。主库把日志发送给从库后不管了，这样会产生一个问题就是假设主库挂了，从库处理失败了，这时候从库升为主库后，**日志就丢失了**。由此产生两个概念。

1. 全同步复制

> 主库写入binlog后强制同步日志到从库，**所有的从库都执行完成后才返回给客户端**，但是很显然这个方式的话性能会受到严重影响。

1. 半同步复制

> 半同步复制的逻辑是这样，从库写入日志成功后返回`ACK`确认给主库，主库收到至少一个从库的确认就认为写操作完成。

### buffer pool

实际上假设我们要更新一行数据，此时数据库会找到这行数据所在的数据页，然后从磁盘文件里把这行数据所在的数据页直接给加载到Buffer Pool里去。

缓冲池的构造如下，磁盘文件的数据页和buffer pool的缓存页一一对应。

![image-20201130170204206](https://gitee.com/adambang/pic/raw/master/20201130170204.png)

**缓存页如何和数据页对应：**

实际上默认情况下，磁盘中存放的数据页的大小是16KB，也就是说，一页数据包含了16KB的内容。
而Buffer Pool中存放的一个一个的数据页，我们通常叫做缓存页，因为毕竟Buffer Pool是一个缓冲池，里面的数据都是从磁盘缓存到内存去的。
而Buffer Pool中默认情况下，一个缓存页的大小和磁盘上的一个数据页的大小是一一对应起来的，都是16KB。  

## 事务

### 事务特性

事务最基本的莫过于 ACID 四个特性了，这四个特性分别是：

**Atomicity：原子性**

事务被视为不可分割的最小单元，事务的所有操作要么全部成功，要么全部失败回滚。

**Consistency：一致性**

数据库在事务执行前后都保持一致性状态，在一致性状态下，所有事务对一个数据的读取结果都是相同的。

**Isolation：隔离性**

一个事务所做的修改在最终提交以前，对其他事务是不可见的。

**Durability：持久性**

一旦事务提交，则其所做的修改将会永远保存到数据库中。即使系统发生崩溃，事务执行的结果也不能丢。

事务的 ACID 特性概念很简单，但不好理解，主要是因为这几个特性不是一种平级关系：

- 只有满足一致性，事务的结果才是正确的。
- 在无并发的情况下，事务串行执行，隔离性一定能够满足。此时只要能满足原子性，就一定能满足一致性。在并发的情况下，多个事务并行执行，事务不仅要满足原子性，还需要满足隔离性，才能满足一致性。
- 事务满足持久化是为了能应对数据库崩溃的情况。

<img src="https://mmbiz.qpic.cn/mmbiz_jpg/uChmeeX1FpwqHyYbEIPyeesNicgZ2s5NTGYL30g0TKLx51l4f5Hs9DUzWicjAgDLrJWse8Aia81kxtuJic5OXIrwBQ/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="img" style="zoom: 50%;" />

### 事务隔离级别

**未提交读（READ UNCOMMITTED）**

事务中的修改，即使没有提交，对其他事务也是可见的。

**提交读（READ COMMITTED）**

一个事务只能读取已经提交的事务所做的修改。换句话说，一个事务所做的修改在提交之前对其他事务是不可见的。

**可重复读（REPEATABLE READ）**

保证在同一个事务中多次读取同样数据的结果是一样的。

**可串行化（SERIALIZABLE）**

强制事务串行执行。



事务问题

脏读（读未提交）：一个事务读取到另外一个事务还没有提交的数据

不可重复读（读提交）：在同一个事务内，两次相同的查询返回了不同的结果（修改）

幻读（可重复读）：同一个事务内多次查询返回的结果集不一样（新增/删除）

### MVCC原理

MVCC：

> 1、全称`Multi-Version Concurrency Control`，即`多版本并发控制`。MVCC是一种并发控制的`理念`，维持一个数据的多个版本，使得读写操作没有冲突。
>
> 2、MVCC在MySQL InnoDB中实现目的主要是为了**提高数据库并发性能**，用更好的方式去处理读-写冲突，做到即使有读写冲突时，也能做到不加锁，非阻塞并发读。

MySQL的RR隔离级别可通过MVCC避免幻读。MySQL实现MVCC机制的时候，是基于undo log多版本链条+ReadView机制的。

MVCC实现原理主要是依赖记录中的 `四个隐式字段`、`undo日志` 、`Consistent Read View`来实现的。

**四个隐式字段**：

> DB_TRX_ID：
>
> > 6byte，最近修改(修改/插入)事务ID：记录创建这条记录/最后一次修改该记录的`事务ID`
>
> DB_ROLL_PTR
>
> > 7byte，回滚指针，指向这条记录的`上一个版本`（存储于rollback segment里）
>
> DB_ROW_ID
>
> > 6byte，隐含的自增ID（`隐藏主键`），如果数据表没有主键，InnoDB会自动以DB_ROW_ID产生一个聚簇索引
>
> FLAG
>
> > 一个删除flag隐藏字段, 既记录被更新或删除并不代表真的删除，而是删除flag变了

执行一个事务的时候，就给你生成一个**ReadView** ，里面比较关键的东西有4个

- m_ids，这个就是说此时有哪些事务在MySQL里执行还没提交的；
- min_trx_id，就是m_ids里最小的值；
- max_trx_id，这是说mysql下一个要生成的事务id，就是最大事务id；
- creator_trx_id，就是本事务的id  

**MySQL InnoDB下的当前读和快照读**

1. 当前读

> 1、像`select lock in share mode`(共享锁)、`select for update` 、`update`、`insert`、`delete`(排他锁)这些操作都是一种`当前读`，就是它读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对`读取的记录进行加锁`。
>
> 2、当前读可以认为是`悲观锁`的具体功能实现

2. 快照读

> 1、不加锁的select就是快照读，即不加锁的非阻塞读；快照读的前提是隔离级别不是串行级别，串行级别下的快照读会退化成当前读；之所以出现快照读的情况，是基于提高并发性能的考虑，快照读的实现是基于多版本并发控制，即`MVCC`，可以认为`MVCC是行锁的一个变种`，但它在很多情况下，`避免了加锁操作`，降低了开销；既然是基于多版本，即快照读可能读到的并不一定是数据的最新版本，而有可能是之前的历史版本。
>
> 2、快照读就是MVCC思想在MySQL的具体非阻塞读功能实现，MVCC的目的就是为了实现读-写冲突不加锁，提高并发读写性能，而这个读指的就是`快照读`。
>
> 3、快照读就是MySQL为我们实现MVCC理想模型的其中一个具体非阻塞读功能。

`重点`：

> 1、事务中快照读的结果是`非常依赖`该事务首次出现快照读的地方，即某个事务中首次出现快照读的地方非常关键，它有决定该事务后续快照读结果的能力。
>
> 2、在`RC`隔离级别下，是每个快照读`都会生成`并获取最新的Read View；而在`RR`隔离级别下，则是同一个事务中的`第一个`快照读才会创建Read View, 之后的快照读获取的都是`同一个`Read View。

### MVCC下的事务

ReadView机制，是基于undo log版本链条实现的一套读视图机制。当前事务生成一个ReadView，当前事务自己更新的数据可以读到的，或者是生成ReadView之前提交的事务修改的值，也是可以读取到的。  

**RC**

RC是每次读取都生成一个新的readview，保证整个事务中读到其他修改提交后的最新值 。

**RR**

RR是整个事务中生成一个readview，第一次查询就会生成一个ReadView。对自己查询的部分添加间隙锁，防止被插入删除。

> **幻读**：在InnoDB的可重复度隔离级别下，使用当前读，一个事务前后两次查询同一个范围，后一次查询会看到期间新插入的行；
>
> **幻读的影响**：会导致一个事务中先产生的锁，无法锁住后加入的行，会产生数据一致性问题；
>
> **产生幻读的原因**：行锁只能锁住一行，不能避免新插入的记录；
>
> **解决幻读**：在两行记录之间加上间隙锁，阻止新纪录的插入，与间隙锁产生冲突的只有“往这个间隙插入记录”这个操作；
>
> 同时添加间隙锁与行锁称为**Next-key lock**，注意间隙锁只有在InnoDB的可重复度隔离级别下生效；
>
> MVCC只实现读取已提交和可重复读，InnoDB在可重复度的隔离级别下，使用MVCC+Next-key lock解决幻读

## 锁

根据加锁的范围，MySQL 里面的锁大致可以分成全局锁、表级锁和行锁三类。

### 全局锁

顾名思义，全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。

**全局锁的典型使用场景是，做全库逻辑备份。**不加锁的情况：在可重复读隔离级别下开启一个事务，获取一致性视图。

风险

- 如果在主库备份，在备份期间不能更新，业务停摆
- 如果在从库备份，备份期间不能执行主库同步的binlog，导致主从延迟

### 表级锁

MySQL 里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。

**表锁**

- 表锁的语法是 lock tables … read/write
- 可以用unlock tables主动释放锁，也可以在客户端断开时自动释放

**元数据锁（MDL)**

- MDL 不需要显式使用，在访问一个表的时候会被自动加上，保证读写的正确性
- 当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。
- 读读不互斥，读写/写写互斥

### 行锁

MySQL 的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如 MyISAM 引擎就不支持行锁。

在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时(提交)才释放。这个就是**两阶段锁协议**。

> 如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。

### 死锁和死锁检测

当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为**死锁**。

当出现死锁以后，有两种策略：

- 一种策略是，直接进入**等待**，直到**超时**。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。

- 另一种策略是，发起**死锁检测**，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。

  超时时间设置过长影响业务，设置过短锁失去意义。

  死锁检测每个加锁的事务都要进行死锁判断，要耗费大量的 CPU 资源。

  解决方法：  

  1. 能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。（可能造成超时，业务有损）

  2. 控制并发度

## 索引

MySQL官方对索引的定义为：索引(Index)是帮助MySQL高效获取数据的数据结构。

### 数据结构

二叉查找树

- 查找耗时与树的深度相关的，最坏时间复杂度会退化成O(n)

平衡二叉树

- 左右子树深度差绝对值不能超过 1
- 插入/删除节点，需要频繁调整树结构，性能较差
- 树的深度过深，磁盘IO开销较大

红黑树

- 叶子节点全黑，一红带两黑，弱平衡性
- 适用于删除插入操作较多的情况

B树

- 叶子节点，非叶子节点，都存储数据
- 中序遍历，可以获得所有节点

B+树

- 非叶子节点不再存储数据，数据只存储在同一层的叶子节点上
- 叶子之间，增加了链表，获取所有节点，不再需要中序遍历

### 索引分类

**结构**

- B树索引
- Hash索引
- 全文索引
- R-Tree 索引

类型

- 单值索引

- 唯一索引

- 复合索引

  - 覆盖索引

    查询的列刚好与创建的索引列的列名及顺序全部匹配或者部分匹配

### 索引创建场景

**哪些情况需要创建索引**

- 1.主键自动建立唯一索引

- 2.频繁作为查询的条件的字段应该创建索引

- 3.查询中与其他表关联的字段，外键关系建立索引

- 4.频繁更新的字段不适合创建索引

  因为每次更新不单单是更新了记录还会更新索引，加重IO负担

- 5.Where条件里用不到的字段不创建索引

- 6.单一索引/复合索引的选择问题，平时选择哪一个？who？（在高并发下倾向创建组合索引）

- 7.查询中排序（order by）的字段，排序字段若通过索引去访问将大大提高排序的速度

  比如你创建复合索引（name,age,address），那么排序的时候如果还按照name,age,address排序，速度会非常快。

- 8.查询中统计或者分组（group by）字段

**哪些情况不要创建索引**

- 1.表记录太少

  mysql虽然官方说能撑得住500到800万，但是实际上，300万条数据，性能就开始下降。

- 2.经常增删改的表

- 3.数据重复且分布平均的表字段，因此应该只为经常查询和经常排序的数据列建立索引。 

  比如国籍，省市县，男女，这样的数据重复率高，这样的就不适合建索引。

  注意，如果某个数据列包含许多重复的内容，为它建立索引就没有太大的实际效果。